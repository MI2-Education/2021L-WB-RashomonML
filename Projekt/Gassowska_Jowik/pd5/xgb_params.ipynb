{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import mp_utils as mp\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.\\data\\data_compressed\\df_data.csv')\n",
    "co = pd.read_csv('.\\data\\data_compressed\\df_cohort.csv')\n",
    "df_static = pd.read_csv('.\\data\\data_compressed\\df_static_data.csv')\n",
    "df_death = pd.read_csv('.\\data\\data_compressed\\df_death.csv')\n",
    "co = co.drop(co.columns[0], axis=1)\n",
    "df_static = df_static.drop(df_static.columns[0], axis=1)\n",
    "df_death = df_death.drop(df_death.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_min, var_max, var_first, var_last, var_sum, var_first_early, var_last_early, var_static = mp.vars_of_interest()\n",
    "sid = np.sort(np.unique(df_death['subject_id'].values))\n",
    "\n",
    "\n",
    "W = 24\n",
    "W_extra = 24\n",
    "y_outcome_label = 'death_in_hospital'\n",
    "\n",
    "df_tmp=co.copy().set_index('icustay_id')\n",
    "time_dict = df_tmp.copy()\n",
    "time_dict['windowtime'] = W\n",
    "time_dict = time_dict['windowtime'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-19 14:06:46.925729 - Finished fold 1 of 5. AUROC 0.885.\n",
      "2021-04-19 14:17:26.212363 - Finished fold 2 of 5. AUROC 0.887.\n",
      "2021-04-19 14:32:32.428986 - Finished fold 3 of 5. AUROC 0.878.\n",
      "2021-04-19 14:54:47.993055 - Finished fold 4 of 5. AUROC 0.892.\n",
      "2021-04-19 15:05:37.829748 - Finished fold 5 of 5. AUROC 0.894.\n",
      "\n",
      "Best params: {'xgb__subsample': 0.7, 'xgb__reg_lambda': 0.1, 'xgb__n_estimators': 300, 'xgb__min_child_weight': 3.0, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.5, 'xgb__colsample_bytree': 0.6, 'xgb__colsample_bylevel': 0.9}\n",
      "\n",
      "StudyName,SampleSize, xgb \n",
      "baseline,38687,0.887036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_study = 'baseline'\n",
    "exclFcn = lambda x: x.loc[x['inclusion_stay_ge_24hr']& ( (x['censortime_hours'].isnull()) | (x['censortime_hours']>=24) ) ,'icustay_id'].values\n",
    "    \n",
    "# Data preparation\n",
    "df_data = mp.get_design_matrix(df, time_dict, W=W, W_extra=W_extra)\n",
    "iid_keep = exclFcn(co)\n",
    "df_data = df_data.reindex(index = iid_keep)\n",
    "X = df_data.merge(df_static.set_index('icustay_id')[var_static], how='left', left_index=True, right_index=True)\n",
    "X = X.merge(co.set_index('icustay_id')[[y_outcome_label]], left_index=True, right_index=True)\n",
    "X = X.merge(co.set_index('icustay_id')[['subject_id']], left_index=True, right_index=True)\n",
    "idxMap = np.searchsorted(sid, X['subject_id'].values)\n",
    "\n",
    "# assign k-fold\n",
    "K = 5\n",
    "np.random.seed(871)\n",
    "idxK_sid = np.random.permutation(sid.shape[0])\n",
    "idxK_sid = np.mod(idxK_sid,K)\n",
    "\n",
    "idxK = idxK_sid[idxMap]\n",
    "X.drop('subject_id',axis=1,inplace=True)\n",
    "X = X.values\n",
    "y = X[:,-1]\n",
    "X = X[:,0:-1]\n",
    "\n",
    "# Model evaluation\n",
    "mdl_val = list()\n",
    "results_val = list() # initialize list for scores\n",
    "pred_val = list()\n",
    "tar_val = list()\n",
    "\n",
    "# Hyperparameters tuning\n",
    "# no pre-processing of data necessary for xgb\n",
    "model_pipeline = Pipeline([('xgb', xgb.XGBClassifier())])\n",
    "\n",
    "param_grid = {\n",
    "        'xgb__max_depth': [1, 3, 6, 8, 10],\n",
    "        'xgb__learning_rate': [0.001, 0.05, 0.01, 0.1],\n",
    "        'xgb__subsample': [0.5, 0.7, 0.9, 1.0],\n",
    "        'xgb__colsample_bytree': [0.4, 0.6, 0.8, 1.0],\n",
    "        'xgb__colsample_bylevel': [0.5, 0.7, 0.9, 1.0],\n",
    "        'xgb__min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "        'xgb__gamma': [0, 0.25, 0.5, 1.0],\n",
    "        'xgb__reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "        'xgb__n_estimators': [100, 200, 300, 400]}\n",
    "fit_params = {'xgb__eval_metric': 'logloss'}\n",
    "\n",
    "\n",
    "estimator = RandomizedSearchCV(model_pipeline, param_grid, cv=5)\n",
    "\n",
    "for k in range(K):\n",
    "    # train the model using all but the kth fold\n",
    "    curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k], **fit_params)\n",
    "    curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "    curr_prob = curr_prob[:,1]\n",
    "\n",
    "    pred_val.append(curr_prob)\n",
    "    tar_val.append(y[idxK == k])\n",
    "\n",
    "    # calculate score (AUROC)\n",
    "    curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "    results_val.append(curr_score)\n",
    "\n",
    "    print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))\n",
    "\n",
    "# Final results print\n",
    "best_params = estimator.best_params_\n",
    "print('')\n",
    "print(\"Best params: {}\".format(best_params))\n",
    "print('')\n",
    "print('StudyName,SampleSize',end='')\n",
    "print(', xgb ',end='')\n",
    "print('')\n",
    "print( '{},{}'.format(current_study, X.shape[0] ), end='' )\n",
    "print(',{:0.6f}'.format(np.mean(results_val) ), end='')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original model cv AUCROC scores:\n",
    "##  Fold 1 of 5. AUROC 0.880.\n",
    "##  Fold 2 of 5. AUROC 0.889.\n",
    "##  Fold 3 of 5. AUROC 0.888.\n",
    "##  Fold 4 of 5. AUROC 0.886.\n",
    "##  Fold 5 of 5. AUROC 0.897.\n",
    "\n",
    "# Original params: max_depth=3, n_estimators=300, learning_rate=0.05\n",
    "\n",
    "# Original model final result:\n",
    "# StudyName,SampleSize,xgb\n",
    "# baseline,38687,0.887931"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-19 15:36:52.718529 - Finished fold 1 of 5. AUROC 0.885.\n",
      "2021-04-19 15:45:21.796123 - Finished fold 2 of 5. AUROC 0.887.\n",
      "2021-04-19 15:55:15.375815 - Finished fold 3 of 5. AUROC 0.878.\n",
      "2021-04-19 16:06:56.798799 - Finished fold 4 of 5. AUROC 0.892.\n",
      "2021-04-19 16:16:18.863232 - Finished fold 5 of 5. AUROC 0.894.\n",
      "\n",
      "Best params: {'xgb__subsample': 0.7, 'xgb__reg_lambda': 0.1, 'xgb__n_estimators': 300, 'xgb__min_child_weight': 3.0, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.5, 'xgb__colsample_bytree': 0.6, 'xgb__colsample_bylevel': 0.9}\n",
      "\n",
      "StudyName,SampleSize, xgb \n",
      "baseline_withdrawal,38687,0.887036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_study = 'baseline_withdrawal'\n",
    "exclFcn = lambda x: x.loc[x['inclusion_stay_ge_24hr']& ( (x['censortime_hours'].isnull()) | (x['censortime_hours']>=24) ) ,'icustay_id'].values    \n",
    "# Data preparation\n",
    "df_data = mp.get_design_matrix(df, time_dict, W=W, W_extra=W_extra)\n",
    "iid_keep = exclFcn(co)\n",
    "df_data = df_data.reindex(index = iid_keep)\n",
    "X = df_data.merge(df_static.set_index('icustay_id')[var_static], how='left', left_index=True, right_index=True)\n",
    "X = X.merge(co.set_index('icustay_id')[[y_outcome_label]], left_index=True, right_index=True)\n",
    "X = X.merge(co.set_index('icustay_id')[['subject_id']], left_index=True, right_index=True)\n",
    "idxMap = np.searchsorted(sid, X['subject_id'].values)\n",
    "\n",
    "# assign k-fold\n",
    "K = 5\n",
    "np.random.seed(871)\n",
    "idxK_sid = np.random.permutation(sid.shape[0])\n",
    "idxK_sid = np.mod(idxK_sid,K)\n",
    "\n",
    "idxK = idxK_sid[idxMap]\n",
    "X.drop('subject_id',axis=1,inplace=True)\n",
    "X = X.values\n",
    "y = X[:,-1]\n",
    "X = X[:,0:-1]\n",
    "\n",
    "\n",
    "# Model evaluation\n",
    "mdl_val = list()\n",
    "results_val = list() # initialize list for scores\n",
    "pred_val = list()\n",
    "tar_val = list()\n",
    "\n",
    "# Hyperparameters tuning\n",
    "# no pre-processing of data necessary for xgb\n",
    "model_pipeline = Pipeline([('xgb', xgb.XGBClassifier())])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "        'xgb__max_depth': [1, 3, 6, 8, 10],\n",
    "        'xgb__learning_rate': [0.001, 0.05, 0.01, 0.1],\n",
    "        'xgb__subsample': [0.5, 0.7, 0.9, 1.0],\n",
    "        'xgb__colsample_bytree': [0.4, 0.6, 0.8, 1.0],\n",
    "        'xgb__colsample_bylevel': [0.5, 0.7, 0.9, 1.0],\n",
    "        'xgb__min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "        'xgb__gamma': [0, 0.25, 0.5, 1.0],\n",
    "        'xgb__reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "        'xgb__n_estimators': [100, 200, 300, 400]}\n",
    "\n",
    "fit_params = {'xgb__eval_metric': 'logloss'}\n",
    "\n",
    "estimator = RandomizedSearchCV(model_pipeline, param_grid, cv=5)\n",
    "\n",
    "for k in range(K):\n",
    "    # train the model using all but the kth fold\n",
    "    curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k], **fit_params)\n",
    "    curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "    curr_prob = curr_prob[:,1]\n",
    "\n",
    "    pred_val.append(curr_prob)\n",
    "    tar_val.append(y[idxK == k])\n",
    "\n",
    "    # calculate score (AUROC)\n",
    "    curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "    results_val.append(curr_score)\n",
    "\n",
    "    print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))\n",
    "        \n",
    "\n",
    "\n",
    "# Final results print\n",
    "best_params = estimator.best_params_\n",
    "print('')\n",
    "print(\"Best params: {}\".format(best_params))\n",
    "print('')\n",
    "print('StudyName,SampleSize',end='')\n",
    "print(', xgb ',end='')\n",
    "print('')\n",
    "print( '{},{}'.format(current_study, X.shape[0] ), end='' )\n",
    "print(',{:0.6f}'.format(np.mean(results_val) ), end='')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original model cv AUCROC scores:\n",
    "##  Fold 1 of 5. AUROC 0.880.\n",
    "##  Fold 2 of 5. AUROC 0.889.\n",
    "##  Fold 3 of 5. AUROC 0.888.\n",
    "##  Fold 4 of 5. AUROC 0.886.\n",
    "##  Fold 5 of 5. AUROC 0.897.\n",
    "\n",
    "# Original params: max_depth=3, n_estimators=300, learning_rate=0.05\n",
    "\n",
    "# Original model final result:\n",
    "# StudyName,SampleSize,xgb\n",
    "# baseline_withdrawal,38687,0.887931"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
